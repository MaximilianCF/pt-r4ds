# Tornando os dados _tidy_ {#sec-data-tidy}

```{r}
#| echo: false

source("_common.R")
```

## Introdução 

> "Todas as famílias felizes se parecem, cada família infeliz é infeliz à sua maneira."\
> --- Leo Tolstoy

> "Todos os conjuntos de dados organizados se parecem, cada conjunto de dados bagunçados são bagunçados à sua maneira."\
> --- Hadley Wickham

Neste capítulo, você vai aprender uma forma consistente de organizar seus dados no R utilizando um sistema chamado **tidy data**.
Colocar seus dados nesse formato requer alguma preparação, mas esse é um trabalho que se paga a longo prazo.
Uma vez que você tenha em mãos os dados no formato _tidy_ e as ferramentas do tidyverse, você irá gastar muito menos tempo alternando seus dados entre uma representação e outra, de forma que o tempo com seus dados possa ser gasto nas questões que você realmente se importa.

Neste capítulo, você primeiro vai aprender sobre a definição do formato _tidy_ e vê-lo sendo aplicado em um conjunto de dados simulado.
Em seguida, você vai mergulhar na principal ferramenta que utilizará para organizar os dados: a pivotagem.
Pivotar lhe permite mudar a forma dos dados sem modificar nenhum de seus valores.

### Pré-requisitos

Neste capítulo, vamos focar no `tidyr`, um pacote que disponibliza uma variedade de ferramentas para te ajudar a organizar seus conjuntos de dados bagunçados.
`tidyr` é faz parte do coração do tidyverse.

```{r}
#| label: setup
#| message: false

library(tidyverse)
```

Deste capítulo em diante, vamos suprimir a mensagem de carregamento `library(tidyverse)`.

## Dados _tidy_ {#sec-tidy-data}

É possível representar os mesmos dados de diversas formas.
O exemplo abaixo mostra os mesmos dados organizados de três formas diferentes.
Cada conjunto de dados mostra os mesmos valores de quatro variáveis: *país*, *ano*, *população*, e o número de *casos* documentados de TB (tuberculose). No entanto, cada conjunto de dados organiza os valores de uma forma diferente.

```{r}
table1

table2

table3
```

Todas essas são representações dos mesmos dados. Mas nem todas são igualmente fáceis de se utilizar.
Uma delas, `table1`, será muito mais fácil de trabalhar dentro do tidyverse porque está no formato **tidy**.

Existem três regras interrelacionadas que fazem com que um conjunto de dados seja considerado _tidy_:

1.  Cada variável é uma coluna; cada coluna é uma variável.
2.  Cada observação é uma linha; cada linha é uma observação.
3.  Cada valor é uma célula; cada célula é um único valor.

@fig-tidy-structure mostra essas regras visualmente. 

```{r}
#| label: fig-tidy-structure
#| echo: false
#| fig-cap: | 
#|   As seguintes três regras tornam um conjunto de dados tidy: variáveis são colunas,
#|   observações são linhas e valores são células.
#| fig-alt: | 
#|   Três painéis, cada um representando um data frame em formato tidy. O primeiro painel
#|   mostra que cada variável é uma coluna. O segundo painel mostra que cada
#|   observação é uma linha. O terceiro painel mostra que cada valor é
#|   uma célula.

knitr::include_graphics("images/tidy-1.png", dpi = 270)
```

Por que garantir que seus dados estão no formato _tidy_?
Existem duas principais vantagens:

1.  Há uma vantagem generalizada em escolher uma forma consistente de armazenar os dados.
    Se você tiver uma estrutura de dados consistente, é mais fácil compreender as ferramentas adequadas a ela, pois ela terá uma uniformidade subjacente. 

2.  Há uma vantagem específica em colocar as variáveis em colunas porque isso permite que a natureza vetorial do R possa brilhar. 
    Como você aprendeu em @sec-mutate e @sec-summarize, a maioria das funções nativas do R trabalham com vetores de valores.
    Isso torna natural as transformações sobre dados no formato _tidy_. 

`dplyr`, `ggplot2`, e todos os demais pacotes do tidyverse foram pensados para trabalhar com dados _tidy_.
Aqui estão alguns pequenos exemplos mostrando como é possível trabalhar com `table1`.

```{r}
#| fig-width: 5
#| fig-alt: |
#|   Essa figura mostra o número de casos em 1999 e 2000 para 
#|   Afeganistão, Brasil e China, com ano no eixo-x e o número 
#|   de casos no eixo-y. Cada ponto no gráfico representa o número
#|   de casos em um dado país em um dado ano. Os pontos para cada
#|   país são diferenciados dos outros por cor e forma e estão conectados
#|   por uma linha, resultando em três linhas não paralelas e sem interseção. 
#|   Os números de casos na China são mais altos tanto para 1999 quanto para 2000, com
#|   valores acima de 200,000 para ambos os anos. O número de casos no Brasil é de
#|   aproximadamente 40,000 em 1999 e aproximadamente 75,000 em 2000. O 
#|   número de casos no Afeganistão são os mais baixos tanto para 1999 quanto para 2000, com
#|   valores que parecem estar muito perto do 0 nessa escala.

# Calcular a taxa (rate) por 10,000
table1 |>
  mutate(rate = cases / population * 10000)

# Calcular o total de casos por ano 
table1 |> 
  group_by(year) |> 
  summarize(total_cases = sum(cases))

# Visualizar mudanças ao longo do tempo
ggplot(table1, aes(x = year, y = cases)) +
  geom_line(aes(group = country), color = "grey50") +
  geom_point(aes(color = country, shape = country)) +
  scale_x_continuous(breaks = c(1999, 2000)) # quebras (breaks) no eixo-x em 1999 and 2000
```

### Exercícios

1.  Para cada uma das tabelas do exemplo, descreva o que cada observação e cada coluna representa.

2.  Faça um esboço do processo que você usaria para calcular `rate` para a `table2` e `table3`.
    Você precisará executar quatro operações: 

    a.  Extrair o número de casos de TB por país por ano.
    b.  Extrair a população correspondente por país por ano.
    c.  Dividir os casos pela população e multiplicar por 10000.
    d.  Armazenar de volta no local apropriado.

    Você ainda não aprendeu todas as funções necessárias para, de fato, executar essas operações, mas ainda assim você deve ser capaz de pensar sobre as transformações que você precisaria.

## Lengthening data {#sec-pivoting}

The principles of tidy data might seem so obvious that you wonder if you'll ever encounter a dataset that isn't tidy.
Unfortunately, however, most real data is untidy.
There are two main reasons:

1.  Data is often organized to facilitate some goal other than analysis.
    For example, it's common for data to be structured to make data entry, not analysis, easy.

2.  Most people aren't familiar with the principles of tidy data, and it's hard to derive them yourself unless you spend a lot of time working with data.

This means that most real analyses will require at least a little tidying.
You'll begin by figuring out what the underlying variables and observations are.
Sometimes this is easy; other times you'll need to consult with the people who originally generated the data.
Next, you'll **pivot** your data into a tidy form, with variables in the columns and observations in the rows.

tidyr provides two functions for pivoting data: `pivot_longer()` and `pivot_wider()`.
We'll first start with `pivot_longer()` because it's the most common case.
Let's dive into some examples.

### Data in column names {#sec-billboard}

The `billboard` dataset records the billboard rank of songs in the year 2000:

```{r}
billboard
```

In this dataset, each observation is a song.
The first three columns (`artist`, `track` and `date.entered`) are variables that describe the song.
Then we have 76 columns (`wk1`-`wk76`) that describe the rank of the song in each week[^data-tidy-1].
Here, the column names are one variable (the `week`) and the cell values are another (the `rank`).

[^data-tidy-1]: The song will be included as long as it was in the top 100 at some point in 2000, and is tracked for up to 72 weeks after it appears.

To tidy this data, we'll use `pivot_longer()`:

```{r, R.options=list(pillar.print_min = 10)}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank"
  )
```

After the data, there are three key arguments:

-   `cols` specifies which columns need to be pivoted, i.e. which columns aren't variables. This argument uses the same syntax as `select()` so here we could use `!c(artist, track, date.entered)` or `starts_with("wk")`.
-   `names_to` names the variable stored in the column names, we named that variable `week`.
-   `values_to` names the variable stored in the cell values, we named that variable `rank`.

Note that in the code `"week"` and `"rank"` are quoted because those are new variables we're creating, they don't yet exist in the data when we run the `pivot_longer()` call.

Now let's turn our attention to the resulting, longer data frame.
What happens if a song is in the top 100 for less than 76 weeks?
Take 2 Pac's "Baby Don't Cry", for example.
The above output suggests that it was only in the top 100 for 7 weeks, and all the remaining weeks are filled in with missing values.
These `NA`s don't really represent unknown observations; they were forced to exist by the structure of the dataset[^data-tidy-2], so we can ask `pivot_longer()` to get rid of them by setting `values_drop_na = TRUE`:

[^data-tidy-2]: We'll come back to this idea in @sec-missing-values.

```{r}
billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  )
```

The number of rows is now much lower, indicating that many rows with `NA`s were dropped.

You might also wonder what happens if a song is in the top 100 for more than 76 weeks?
We can't tell from this data, but you might guess that additional columns `wk77`, `wk78`, ... would be added to the dataset.

This data is now tidy, but we could make future computation a bit easier by converting values of `week` from character strings to numbers using `mutate()` and `readr::parse_number()`.
`parse_number()` is a handy function that will extract the first number from a string, ignoring all other text.

```{r}
billboard_longer <- billboard |> 
  pivot_longer(
    cols = starts_with("wk"), 
    names_to = "week", 
    values_to = "rank",
    values_drop_na = TRUE
  ) |> 
  mutate(
    week = parse_number(week)
  )
billboard_longer
```

Now that we have all the week numbers in one variable and all the rank values in another, we're in a good position to visualize how song ranks vary over time.
The code is shown below and the result is in @fig-billboard-ranks.
We can see that very few songs stay in the top 100 for more than 20 weeks.

```{r}
#| label: fig-billboard-ranks
#| fig-cap: |
#|   A line plot showing how the rank of a song changes over time.
#| fig-alt: |
#|   A line plot with week on the x-axis and rank on the y-axis, where
#|   each line represents a song. Most songs appear to start at a high rank,
#|   rapidly accelerate to a low rank, and then decay again. There are
#|   surprisingly few tracks in the region when week is >20 and rank is
#|   >50.

billboard_longer |> 
  ggplot(aes(x = week, y = rank, group = track)) + 
  geom_line(alpha = 0.25) + 
  scale_y_reverse()
```

### How does pivoting work?

Now that you've seen how we can use pivoting to reshape our data, let's take a little time to gain some intuition about what pivoting does to the data.
Let's start with a very simple dataset to make it easier to see what's happening.
Suppose we have three patients with `id`s A, B, and C, and we take two blood pressure measurements on each patient.
We'll create the data with `tribble()`, a handy function for constructing small tibbles by hand:

```{r}
df <- tribble(
  ~id,  ~bp1, ~bp2,
   "A",  100,  120,
   "B",  140,  115,
   "C",  120,  125
)
```

We want our new dataset to have three variables: `id` (already exists), `measurement` (the column names), and `value` (the cell values).
To achieve this, we need to pivot `df` longer:

```{r}
df |> 
  pivot_longer(
    cols = bp1:bp2,
    names_to = "measurement",
    values_to = "value"
  )
```

How does the reshaping work?
It's easier to see if we think about it column by column.
As shown in @fig-pivot-variables, the values in a column that was already a variable in the original dataset (`id`) need to be repeated, once for each column that is pivoted.

```{r}
#| label: fig-pivot-variables
#| echo: false
#| fig-cap: | 
#|   Columns that are already variables need to be repeated, once for
#|   each column that is pivoted.
#| fig-alt: | 
#|   A diagram showing how `pivot_longer()` transforms a simple
#|   dataset, using color to highlight how the values in the `id` column
#|   ("A", "B", "C") are each repeated twice in the output because there are
#|   two columns being pivoted ("bp1" and "bp2").

knitr::include_graphics("diagrams/tidy-data/variables.png", dpi = 270)
```

The column names become values in a new variable, whose name is defined by `names_to`, as shown in @fig-pivot-names.
They need to be repeated once for each row in the original dataset.

```{r}
#| label: fig-pivot-names
#| echo: false
#| fig-cap: |
#|   The column names of pivoted columns become values in a new column. The 
#|   values need to be repeated once for each row of the original dataset.
#| fig-alt: | 
#|   A diagram showing how `pivot_longer()` transforms a simple
#|   data set, using color to highlight how column names ("bp1" and 
#|   "bp2") become the values in a new `measurement` column. They are repeated
#|   three times because there were three rows in the input.

knitr::include_graphics("diagrams/tidy-data/column-names.png", dpi = 270)
```

The cell values also become values in a new variable, with a name defined by `values_to`.
They are unwound row by row.
@fig-pivot-values illustrates the process.

```{r}
#| label: fig-pivot-values
#| echo: false
#| fig-cap: |
#|   The number of values is preserved (not repeated), but unwound
#|   row-by-row.
#| fig-alt: | 
#|   A diagram showing how `pivot_longer()` transforms data,
#|   using color to highlight how the cell values (blood pressure measurements)
#|   become the values in a new `value` column. They are unwound row-by-row,
#|   so the original rows (100,120), then (140,115), then (120,125), become 
#|   a column running from 100 to 125.

knitr::include_graphics("diagrams/tidy-data/cell-values.png", dpi = 270)
```

### Many variables in column names

A more challenging situation occurs when you have multiple pieces of information crammed into the column names, and you would like to store these in separate new variables.
For example, take the `who2` dataset, the source of `table1` and friends that you saw above:

```{r}
who2
```

This dataset, collected by the World Health Organisation, records information about tuberculosis diagnoses.
There are two columns that are already variables and are easy to interpret: `country` and `year`.
They are followed by 56 columns like `sp_m_014`, `ep_m_4554`, and `rel_m_3544`.
If you stare at these columns for long enough, you'll notice there's a pattern.
Each column name is made up of three pieces separated by `_`.
The first piece, `sp`/`rel`/`ep`, describes the method used for the diagnosis, the second piece, `m`/`f` is the `gender` (coded as a binary variable in this dataset), and the third piece, `014`/`1524`/`2534`/`3544`/`4554`/`5564`/`65` is the `age` range (`014` represents 0-14, for example).

So in this case we have six pieces of information recorded in `who2`: the country and the year (already columns); the method of diagnosis, the gender category, and the age range category (contained in the other column names); and the count of patients in that category (cell values).
To organize these six pieces of information in six separate columns, we use `pivot_longer()` with a vector of column names for `names_to` and instructors for splitting the original variable names into pieces for `names_sep` as well as a column name for `values_to`:

```{r}
who2 |> 
  pivot_longer(
    cols = !(country:year),
    names_to = c("diagnosis", "gender", "age"), 
    names_sep = "_",
    values_to = "count"
  )
```

An alternative to `names_sep` is `names_pattern`, which you can use to extract variables from more complicated naming scenarios, once you've learned about regular expressions in @sec-regular-expressions.

Conceptually, this is only a minor variation on the simpler case you've already seen.
@fig-pivot-multiple-names shows the basic idea: now, instead of the column names pivoting into a single column, they pivot into multiple columns.
You can imagine this happening in two steps (first pivoting and then separating) but under the hood it happens in a single step because that's faster.

```{r}
#| label: fig-pivot-multiple-names
#| echo: false
#| fig-cap: |
#|   Pivoting columns with multiple pieces of information in the names 
#|   means that each column name now fills in values in multiple output 
#|   columns.
#| fig-alt: |
#|   A diagram that uses color to illustrate how supplying `names_sep` 
#|   and multiple `names_to` creates multiple variables in the output.
#|   The input has variable names "x_1" and "y_2" which are split up
#|   by "_" to create name and number columns in the output. This is
#|   is similar case with a single `names_to`, but what would have been a
#|   single output variable is now separated into multiple variables.

knitr::include_graphics("diagrams/tidy-data/multiple-names.png", dpi = 270)
```

### Data and variable names in the column headers

The next step up in complexity is when the column names include a mix of variable values and variable names.
For example, take the `household` dataset:

```{r}
household
```

This dataset contains data about five families, with the names and dates of birth of up to two children.
The new challenge in this dataset is that the column names contain the names of two variables (`dob`, `name)` and the values of another (`child,` with values 1 or 2).
To solve this problem we again need to supply a vector to `names_to` but this time we use the special `".value"` sentinel; this isn't the name of a variable but a unique value that tells `pivot_longer()` to do something different.
This overrides the usual `values_to` argument to use the first component of the pivoted column name as a variable name in the output.

```{r}
household |> 
  pivot_longer(
    cols = !family, 
    names_to = c(".value", "child"), 
    names_sep = "_", 
    values_drop_na = TRUE
  )
```

We again use `values_drop_na = TRUE`, since the shape of the input forces the creation of explicit missing variables (e.g., for families with only one child).

@fig-pivot-names-and-values illustrates the basic idea with a simpler example.
When you use `".value"` in `names_to`, the column names in the input contribute to both values and variable names in the output.

```{r}
#| label: fig-pivot-names-and-values
#| echo: false
#| fig-cap: |
#|   Pivoting with `names_to = c(".value", "num")` splits the column names
#|   into two components: the first part determines the output column
#|   name (`x` or `y`), and the second part determines the value of the
#|   `num` column.
#| fig-alt: |
#|   A diagram that uses color to illustrate how the special ".value"
#|   sentinel works. The input has names "x_1", "x_2", "y_1", and "y_2",
#|   and we want to use the first component ("x", "y") as a variable name
#|   and the second ("1", "2") as the value for a new "num" column.

knitr::include_graphics("diagrams/tidy-data/names-and-values.png", dpi = 270)
```

## Widening data

So far we've used `pivot_longer()` to solve the common class of problems where values have ended up in column names.
Next we'll pivot (HA HA) to `pivot_wider()`, which makes datasets **wider** by increasing columns and reducing rows and helps when one observation is spread across multiple rows.
This seems to arise less commonly in the wild, but it does seem to crop up a lot when dealing with governmental data.

We'll start by looking at `cms_patient_experience`, a dataset from the Centers of Medicare and Medicaid services that collects data about patient experiences:

```{r}
cms_patient_experience
```

The core unit being studied is an organization, but each organization is spread across six rows, with one row for each measurement taken in the survey organization.
We can see the complete set of values for `measure_cd` and `measure_title` by using `distinct()`:

```{r}
cms_patient_experience |> 
  distinct(measure_cd, measure_title)
```

Neither of these columns will make particularly great variable names: `measure_cd` doesn't hint at the meaning of the variable and `measure_title` is a long sentence containing spaces.
We'll use `measure_cd` as the source for our new column names for now, but in a real analysis you might want to create your own variable names that are both short and meaningful.

`pivot_wider()` has the opposite interface to `pivot_longer()`: instead of choosing new column names, we need to provide the existing columns that define the values (`values_from`) and the column name (`names_from)`:

```{r}
cms_patient_experience |> 
  pivot_wider(
    names_from = measure_cd,
    values_from = prf_rate
  )
```

The output doesn't look quite right; we still seem to have multiple rows for each organization.
That's because, we also need to tell `pivot_wider()` which column or columns have values that uniquely identify each row; in this case those are the variables starting with `"org"`:

```{r}
cms_patient_experience |> 
  pivot_wider(
    id_cols = starts_with("org"),
    names_from = measure_cd,
    values_from = prf_rate
  )
```

This gives us the output that we're looking for.

### How does `pivot_wider()` work?

To understand how `pivot_wider()` works, let's again start with a very simple dataset.
This time we have two patients with `id`s A and B, we have three blood pressure measurements on patient A and two on patient B:

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "B",        "bp1",    140,
  "B",        "bp2",    115, 
  "A",        "bp2",    120,
  "A",        "bp3",    105
)
```

We'll take the values from the `value` column and the names from the `measurement` column:

```{r}
df |> 
  pivot_wider(
    names_from = measurement,
    values_from = value
  )
```

To begin the process `pivot_wider()` needs to first figure out what will go in the rows and columns.
The new column names will be the unique values of `measurement`.

```{r}
df |> 
  distinct(measurement) |> 
  pull()
```

By default, the rows in the output are determined by all the variables that aren't going into the new names or values.
These are called the `id_cols`.
Here there is only one column, but in general there can be any number.

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct()
```

`pivot_wider()` then combines these results to generate an empty data frame:

```{r}
df |> 
  select(-measurement, -value) |> 
  distinct() |> 
  mutate(x = NA, y = NA, z = NA)
```

It then fills in all the missing values using the data in the input.
In this case, not every cell in the output has a corresponding value in the input as there's no third blood pressure measurement for patient B, so that cell remains missing.
We'll come back to this idea that `pivot_wider()` can "make" missing values in @sec-missing-values.

You might also wonder what happens if there are multiple rows in the input that correspond to one cell in the output.
The example below has two rows that correspond to `id` "A" and `measurement` "bp1":

```{r}
df <- tribble(
  ~id, ~measurement, ~value,
  "A",        "bp1",    100,
  "A",        "bp1",    102,
  "A",        "bp2",    120,
  "B",        "bp1",    140, 
  "B",        "bp2",    115
)
```

If we attempt to pivot this we get an output that contains list-columns, which you'll learn more about in @sec-rectangling:

```{r}
df |>
  pivot_wider(
    names_from = measurement,
    values_from = value
  )
```

Since you don't know how to work with this sort of data yet, you'll want to follow the hint in the warning to figure out where the problem is:

```{r}
df |> 
  group_by(id, measurement) |> 
  summarize(n = n(), .groups = "drop") |> 
  filter(n > 1)
```

It's then up to you to figure out what's gone wrong with your data and either repair the underlying damage or use your grouping and summarizing skills to ensure that each combination of row and column values only has a single row.

## Resumo 

Nesse capítulo você aprendeu sobre dados no formato _tidy_: dados que possuem variáveis nas colunas e observações nas linhas.
Dados nesse formato facilitam o trabalho no tidyverse, pois sua estrutura consistente é entendida pela maioria das funções. O principal desafio, então, é transformar dados provenientes de quaisquer estruturas que você receber para o formato _tidy_.
Para esse fim, você aprendeu sobre `pivot_longer()` e `pivot_wider()` que permitem a organização de vários conjuntos de dados que ainda não estejam no formato _tidy_.
Os exemplos apresentados aqui são uma seleção dos vários presentes em `vignette("pivot", package = "tidyr")`, então, se você encontrar algum problema com o qual esse capítulo ainda não é capaz de te ajudar, é uma boa ideia checar nessa _vignette_.

Um outro desafio é o fato de que para certos conjuntos de dados, pode ser impossível especificar se a versão _long_ ou _wide_ é a versão _tidy_.
Isso é, em parte, um reflexo da nossa definição de dados _tidy_, em que dizemos que cada coluna deve conter uma variável, mas não definimos, de fato, **o que é** uma variável (e fazer isso é surpreendentemente difícil.)
É totalmente aceitável dizer, de uma forma pragmática, que uma variável é qualquer coisa que facilite sua análise.
Então, se tiver difícil descobrir como fazer algum tipo de cálculo ou análise, considere alterar a forma como seus dados estão organizados; não tenha medo de voltar para um formato _untidy_, transformá-lo e depois reorganizá-lo conforme necessário!

Se você gostou desse capítulo e quiser saber mais sobre a teoria por trás dele, você pode se aprofundar sobre a história e os fundamentos teóricos no artigo [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) publicado no Journal of Statistical Software.

E agora que você já está escrevendo uma quantidade considerável de código em R, é a hora de aprender um pouco mais sobre como organizar o seu código em arquivos e diretórios.
No próximo capítulo, você irá aprender sobre todas as vantagens dos _scripts_ e projetos, e algumas das várias ferramentas que eles disponibilizam para tornar sua vida mais fácil. 
